{"title":"Blog 3 : Clustering","markdown":{"yaml":{"title":"Blog 3 : Clustering ","author":"Sandhya Vinukonda","date":"2023-12-06","categories":["ML"]},"containsRefs":false,"markdown":"\n\nLet's talk about a fascinating part of machine learning and unsupervised learning. In this world, there's a standout technique known as clustering, where we work with data that doesn't come pre-labeled. Instead, we group similar data points into clusters based on common traits or patterns. This blog will take you through the basics of clustering, its types, and zoom in on two popular clustering buddies: K Means and Hierarchical Clustering.\n\nUnderstanding Clustering:\n\nClustering is like a detective trying to find hidden connections in a bunch of clues (data points). The cool thing is, no one is telling the detective what to look for – the algorithm figures it out on its own.\n\nTypes of Clustering:\n\nHard Clustering:\n\nImagine putting each data point into one exclusive group. That's hard clustering for you.\nClassic example: K Means.\n\nSoft Clustering:\n\nNow, think of data points being chill and belonging to multiple groups with varying levels of closeness. That's soft clustering.\nFuzzy C-Means is a soft clustering star.\n\nDifferent Clustering Models:\n \n Picture 1 \n\nConnectivity Models:\nThese algorithms look at how close data points are to each other.\nExample: Hierarchical Clustering.\n\nCentroid Models:\nThese focus on the center points of clusters.\nK Means is a big player here.\n\nDistribution Models:\nAssume that data points follow a common pattern.\nThink of Gaussian Mixture Models (GMM).\n\nDensity Models:\nThese spot clusters based on where data points crowd up.\nA famous one is DBSCAN.\n\nProminent Clustering Algorithms:\nK Means Clustering:\nIt's like dividing data into clubs based on the average characteristics of each group.\nSimple and efficient – a go-to for many.\n\nHierarchical Clustering:\nThis one builds a family tree of clusters, like tracing your ancestry.\nIt's cool because it allows for nested or overlapping groups.\n\nDifference Between K Means and Hierarchical Clustering:\nHere's the lowdown on how K Means and Hierarchical Clustering differ:\n\nNature of Clusters:\nK Means makes clear-cut groups with no sharing allowed.\nHierarchical Clustering creates a family tree where groups can overlap or nest.\n\nNumber of Clusters:\nK Means needs to know how many groups you want before it starts.\nHierarchical Clustering is more flexible – it generates a tree, and you can decide how many groups later.\n\nComputation Complexity:\nK Means is quicker with the calculations, good for big datasets.\nHierarchical Clustering can take more time, especially with lots of data.\nConclusion:\nIn the unsupervised learning world, clustering is like a superhero revealing hidden patterns in data without anyone giving it a roadmap. Knowing the ins and outs of clustering, the different types, and the quirks of K Means and Hierarchical Clustering gives you a powerful toolkit for finding the stories hidden in your data. As technology races forward, the possibilities for unsupervised learning and clustering are endless, promising discoveries in fields from healthcare to finance.\n\nLet’s Start Coding \n\n1. Import Libraries \n\n2. Read data and clean it \n\n3. Model : K Means \n\n","srcMarkdownNoYaml":"\n\nLet's talk about a fascinating part of machine learning and unsupervised learning. In this world, there's a standout technique known as clustering, where we work with data that doesn't come pre-labeled. Instead, we group similar data points into clusters based on common traits or patterns. This blog will take you through the basics of clustering, its types, and zoom in on two popular clustering buddies: K Means and Hierarchical Clustering.\n\nUnderstanding Clustering:\n\nClustering is like a detective trying to find hidden connections in a bunch of clues (data points). The cool thing is, no one is telling the detective what to look for – the algorithm figures it out on its own.\n\nTypes of Clustering:\n\nHard Clustering:\n\nImagine putting each data point into one exclusive group. That's hard clustering for you.\nClassic example: K Means.\n\nSoft Clustering:\n\nNow, think of data points being chill and belonging to multiple groups with varying levels of closeness. That's soft clustering.\nFuzzy C-Means is a soft clustering star.\n\nDifferent Clustering Models:\n \n Picture 1 \n\nConnectivity Models:\nThese algorithms look at how close data points are to each other.\nExample: Hierarchical Clustering.\n\nCentroid Models:\nThese focus on the center points of clusters.\nK Means is a big player here.\n\nDistribution Models:\nAssume that data points follow a common pattern.\nThink of Gaussian Mixture Models (GMM).\n\nDensity Models:\nThese spot clusters based on where data points crowd up.\nA famous one is DBSCAN.\n\nProminent Clustering Algorithms:\nK Means Clustering:\nIt's like dividing data into clubs based on the average characteristics of each group.\nSimple and efficient – a go-to for many.\n\nHierarchical Clustering:\nThis one builds a family tree of clusters, like tracing your ancestry.\nIt's cool because it allows for nested or overlapping groups.\n\nDifference Between K Means and Hierarchical Clustering:\nHere's the lowdown on how K Means and Hierarchical Clustering differ:\n\nNature of Clusters:\nK Means makes clear-cut groups with no sharing allowed.\nHierarchical Clustering creates a family tree where groups can overlap or nest.\n\nNumber of Clusters:\nK Means needs to know how many groups you want before it starts.\nHierarchical Clustering is more flexible – it generates a tree, and you can decide how many groups later.\n\nComputation Complexity:\nK Means is quicker with the calculations, good for big datasets.\nHierarchical Clustering can take more time, especially with lots of data.\nConclusion:\nIn the unsupervised learning world, clustering is like a superhero revealing hidden patterns in data without anyone giving it a roadmap. Knowing the ins and outs of clustering, the different types, and the quirks of K Means and Hierarchical Clustering gives you a powerful toolkit for finding the stories hidden in your data. As technology races forward, the possibilities for unsupervised learning and clustering are endless, promising discoveries in fields from healthcare to finance.\n\nLet’s Start Coding \n\n1. Import Libraries \n\n2. Read data and clean it \n\n3. Model : K Means \n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"cosmo","title-block-banner":true,"title":"Blog 3 : Clustering ","author":"Sandhya Vinukonda","date":"2023-12-06","categories":["ML"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}